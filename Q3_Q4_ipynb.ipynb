{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "0IrLw72bMLwP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self,feature=None, threshold=None, left=None, right=None,value=None):\n",
        "    self.feature = feature\n",
        "    self.left = left\n",
        "    self.threshold = threshold\n",
        "    self.right = right\n",
        "    self.value = value\n",
        "\n",
        "    '''\n",
        "    Notes regarding the class:-\n",
        "    1. value attribute is only for final leaf node that gives out a value\n",
        "    2. left: for samples satisfying\n",
        "    3. right: for samples not satisfying\n",
        "    4. feature and threshiold together is a condition (age<30)\n",
        "    '''"
      ],
      "metadata": {
        "id": "u3VAvCvNpYtQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier:\n",
        "  def __init__(self,max_depth=None,samplesPerLeaf=1):\n",
        "    self.max_depth=max_depth\n",
        "    self.samplesPerLeaf=samplesPerLeaf\n",
        "    self.root=None\n",
        "\n",
        "  def gini_impurity(self,y):\n",
        "    if(len(y)==0):\n",
        "      return 0\n",
        "    # if there no points located within that region, then gini=0\n",
        "\n",
        "    class_counts={}\n",
        "    for label in y:\n",
        "      if label not in class_counts:\n",
        "        class_counts[label]=0\n",
        "      class_counts[label]+=1\n",
        "\n",
        "    sum=0;\n",
        "    for count in class_counts.values():\n",
        "      prob = count/len(y)\n",
        "      sum+=prob**2\n",
        "    return 1-sum\n",
        "\n",
        "  # gini = 1-(sum of squares of each prob)\n",
        "  def fit(self, X, y):\n",
        "    self.num_classes = len(np.unique(y))\n",
        "    self.num_dims = X.shape[1]\n",
        "    self.root = self.make_tree(X, y, 0)\n",
        "\n",
        "  def best_split(self, X, y):\n",
        "    m,n = X.shape\n",
        "    # m is the number of records\n",
        "    # n is the number of dims\n",
        "\n",
        "    if m<=1:\n",
        "      return None, None\n",
        "\n",
        "    # ie. You cant actually split if there is only 1/0 nodes\n",
        "\n",
        "    min_gini = 1\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "\n",
        "    for feature in range(self.num_dims):\n",
        "      thresholds = np.unique(X[:, feature])\n",
        "\n",
        "      for threshold in thresholds:\n",
        "\n",
        "        left_idx = []\n",
        "\n",
        "        for i in range(m):\n",
        "          if(X[i][feature]<=threshold):\n",
        "            left_idx.append(i)\n",
        "\n",
        "        if len(left_idx) < self.samplesPerLeaf or (m - len(left_idx)) < self.samplesPerLeaf:\n",
        "          continue\n",
        "\n",
        "        left_y = []\n",
        "        right_y = []\n",
        "        for i in range(m):\n",
        "            if i in left_idx:\n",
        "                left_y.append(y[i])\n",
        "            else:\n",
        "                right_y.append(y[i])\n",
        "\n",
        "        num_left = len(left_y)\n",
        "        num_right = len(right_y)\n",
        "        left_gini = self.gini_impurity(left_y)\n",
        "        right_gini = self.gini_impurity(right_y)\n",
        "\n",
        "        weighted_gini = (num_left / m) * left_gini + (num_right / m) * right_gini\n",
        "\n",
        "        if weighted_gini < min_gini:\n",
        "          min_gini = weighted_gini\n",
        "          best_feature = feature\n",
        "          best_threshold = threshold\n",
        "\n",
        "    return best_feature, best_threshold\n",
        "\n",
        "  def make_tree(self, X, y, depth=0):\n",
        "    num_samples, num_features = X.shape\n",
        "    num_classes = len(np.unique(y))\n",
        "\n",
        "    if(self.max_depth is not None and depth>=self.max_depth):\n",
        "      leaf_value = self.most_common_label(y)\n",
        "      return Node(value=leaf_value)\n",
        "\n",
        "    if(self.samplesPerLeaf is not None and num_samples<=self.samplesPerLeaf):\n",
        "      leaf_value = self.most_common_label(y)\n",
        "      return Node(value=leaf_value)\n",
        "\n",
        "    if num_classes==1:\n",
        "      leaf_value = self.most_common_label(y)\n",
        "      return Node(value = leaf_value)\n",
        "\n",
        "    # Base cases (3) have been written\n",
        "    # Recursive function follows\n",
        "\n",
        "    best_feature, best_threshold = self.best_split(X, y)\n",
        "\n",
        "    if best_feature is None:\n",
        "      leaf_value = self.most_common_label(y)\n",
        "      return Node(value=leaf_value)\n",
        "\n",
        "    # Another base case\n",
        "\n",
        "    left_idx = []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "      if(X[i][best_feature]<=best_threshold):\n",
        "        left_idx.append(i)\n",
        "\n",
        "    if len(left_idx) < self.samplesPerLeaf or (num_samples - len(left_idx)) < self.samplesPerLeaf:\n",
        "        leaf_value = self.most_common_label(y)\n",
        "        return Node(value=leaf_value)\n",
        "\n",
        "\n",
        "    left_X = []\n",
        "    left_y = []\n",
        "    right_X = []\n",
        "    right_y = []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        if i in left_idx:\n",
        "            left_X.append(X[i])\n",
        "            left_y.append(y[i])\n",
        "        else:\n",
        "            right_X.append(X[i])\n",
        "            right_y.append(y[i])\n",
        "\n",
        "    # Convert back to numpy arrays\n",
        "    left_X = np.array(left_X)\n",
        "    left_y = np.array(left_y)\n",
        "    right_X = np.array(right_X)\n",
        "    right_y = np.array(right_y)\n",
        "\n",
        "    # Recurse\n",
        "    left_child = self.make_tree(left_X, left_y, depth+1)\n",
        "    right_child = self.make_tree(right_X, right_y, depth+1)\n",
        "\n",
        "    return Node(best_feature, best_threshold, left_child, right_child)\n",
        "\n",
        "  def most_common_label(self, y):\n",
        "    num1=0;\n",
        "    num0=0;\n",
        "\n",
        "    for i in y:\n",
        "      if(i==1):\n",
        "        num1+=1\n",
        "      else:\n",
        "        num0+=1\n",
        "\n",
        "    if(num1>num0):\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def predict(self, x):\n",
        "    node = self.root\n",
        "    while node.value is None:\n",
        "      if(x[node.feature]<=node.threshold):\n",
        "        node = node.left\n",
        "      else:\n",
        "        node = node.right\n",
        "    return node.value\n",
        "\n",
        "  def print_tree(self, node=None, indent=\"\"):\n",
        "        if node is None:\n",
        "            node = self.root\n",
        "\n",
        "        # If leaf node, print value\n",
        "        if node.value is not None:\n",
        "            print(f\"{indent}Predict: {'Yes' if node.value == 1 else 'No'}\")\n",
        "            return\n",
        "\n",
        "        # Print decision criteria\n",
        "        print(f\"{indent}Feature {node.feature} <= {node.threshold}\")\n",
        "\n",
        "        # Print left subtree\n",
        "        print(f\"{indent}Left:\")\n",
        "        self.print_tree(node.left, indent + \"  \")\n",
        "\n",
        "        # Print right subtree\n",
        "        print(f\"{indent}Right:\")\n",
        "        self.print_tree(node.right, indent + \"  \")\n",
        "  def predict_multiple_samples(self, X):\n",
        "    predictions = []\n",
        "    for x in X:\n",
        "        predictions.append(self.predict(x))\n",
        "    return np.array(predictions)"
      ],
      "metadata": {
        "id": "Q_q3qYBzpSvw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = {\n",
        "    'Age': [25, 30, 35, 40, 45, 50, 55, 60],\n",
        "    'Income': ['High', 'High', 'Medium', 'Low', 'Low', 'Low', 'Medium', 'High'],\n",
        "    'Student': ['No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No'],\n",
        "    'Credit_Rating': ['Fair', 'Excellent', 'Fair', 'Fair', 'Fair', 'Excellent', 'Excellent', 'Fair'],\n",
        "    'Buy_Computer': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No']\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "bV99uOpUi4Le"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_features(data):\n",
        "    X = np.zeros((len(data['Age']), 4))\n",
        "    student_map = {'No': 0, 'Yes': 1}\n",
        "    credit_map = {'Fair': 0, 'Excellent': 1}\n",
        "    income_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "\n",
        "    X[:, 0] = data['Age']\n",
        "    X[:, 1] = [income_map[x] for x in data['Income']]\n",
        "    X[:, 2] = [student_map[x] for x in data['Student']]\n",
        "    X[:, 3] = [credit_map[x] for x in data['Credit_Rating']]\n",
        "\n",
        "    y = np.array([1 if val == 'Yes' else 0 for val in data['Buy_Computer']])\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Encode the features\n",
        "X, y = encode_features(data)\n"
      ],
      "metadata": {
        "id": "-ARe5DcNqBev"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fennekin = Classifier(max_depth=3,samplesPerLeaf=1)\n",
        "fennekin.fit(X,y)\n",
        "fennekin.print_tree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoKldnmwjid5",
        "outputId": "086763f6-83be-424d-e73d-e48c4a241b88"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 1 <= 1.0\n",
            "Left:\n",
            "  Feature 0 <= 45.0\n",
            "  Left:\n",
            "    Predict: Yes\n",
            "  Right:\n",
            "    Feature 0 <= 50.0\n",
            "    Left:\n",
            "      Predict: No\n",
            "    Right:\n",
            "      Predict: Yes\n",
            "Right:\n",
            "  Predict: No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy measuremnet on training error\n",
        "\n",
        "predictions = fennekin.predict_multiple_samples(X)\n",
        "accuracy = np.mean(predictions == y)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alHE95eNWfnK",
        "outputId": "e67a822c-25a0-45d0-e1f2-8e731e5439f9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction a test sample\n",
        "\n",
        "test_X = [42, 0, 0, 1]\n",
        "test_Y = fennekin.predict(test_X)\n",
        "print(test_Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rfvrS9JPjFs",
        "outputId": "c09199fa-6337-415c-bf74-3d8dd43f77b1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagging with OOB error\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "\n",
        "class BaggedClassifier:\n",
        "    def __init__(self, n_estimators=10, max_depth=None, min_samples_leaf=1):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.trees = []\n",
        "        self.oob_score = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples = len(X)\n",
        "        self.oob_predictions = {i: [] for i in range(n_samples)}\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            b_indices = []\n",
        "            for _ in range(n_samples):\n",
        "                b_indices.append(randrange(n_samples))\n",
        "\n",
        "\n",
        "            b_set = set(b_indices)\n",
        "            oob_indices = [i for i in range(n_samples) if i not in b_set]\n",
        "\n",
        "\n",
        "            X_b = []\n",
        "            y_b = []\n",
        "            for idx in b_indices:\n",
        "                X_b.append(X[idx])\n",
        "                y_b.append(y[idx])\n",
        "\n",
        "\n",
        "            X_b = np.array(X_b)\n",
        "            y_b = np.array(y_b)\n",
        "\n",
        "\n",
        "            tree = Classifier(max_depth=self.max_depth, samplesPerLeaf=self.min_samples_leaf)\n",
        "            tree.fit(X_b, y_b)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "\n",
        "            for idx in oob_indices:\n",
        "                prediction = tree.predict(X[idx])\n",
        "                self.oob_predictions[idx].append(prediction)\n",
        "\n",
        "        oob_errors = 0\n",
        "        oob_total = 0\n",
        "\n",
        "        for idx, predictions in self.oob_predictions.items():\n",
        "            if len(predictions) > 0:\n",
        "                counts = {}\n",
        "                for pred in predictions:\n",
        "                    if pred not in counts:\n",
        "                        counts[pred] = 0\n",
        "                    counts[pred] += 1\n",
        "\n",
        "                majority_vote = max(counts, key=counts.get)\n",
        "                if majority_vote != y[idx]:\n",
        "                    oob_errors += 1\n",
        "                oob_total += 1\n",
        "\n",
        "\n",
        "        if oob_total > 0:\n",
        "            self.oob_score = 1 - (oob_errors / oob_total)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "\n",
        "        for sample in X:\n",
        "\n",
        "            votes = []\n",
        "            for tree in self.trees:\n",
        "                votes.append(tree.predict(sample))\n",
        "\n",
        "\n",
        "            counts = {}\n",
        "            for vote in votes:\n",
        "                if vote not in counts:\n",
        "                    counts[vote] = 0\n",
        "                counts[vote] += 1\n",
        "\n",
        "\n",
        "            majority_class = max(counts, key=counts.get)\n",
        "            predictions.append(majority_class)\n",
        "\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "id": "Mq4qkDQGV7Zd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag = BaggedClassifier(10,3,1)\n",
        "bag.fit(X,y)\n",
        "# Printing scores\n",
        "print(f\"OOB Score: {bag.oob_score * 100:.2f}%\")\n",
        "print(f\"OOb Error: {1-bag.oob_score: .2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfQSMrsaXOsY",
        "outputId": "4f67cfc6-8aad-49d6-d1fd-a1f52db6fef6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 37.50%\n",
            "OOb Error:  0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import randrange, sample\n",
        "\n",
        "class RandomForestClassifier:\n",
        "    def __init__(self, n_estimators=10, max_depth=None, min_samples_leaf=1, max_features=2):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.max_features = max_features  # Number of features to consider for each split\n",
        "        self.trees = []\n",
        "        self.oob_score = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples = len(X)\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        self.max_features = min(self.max_features, n_features)\n",
        "\n",
        "        self.oob_predictions = {i: [] for i in range(n_samples)}\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            b_indices = []\n",
        "            for _ in range(n_samples):\n",
        "                b_indices.append(randrange(n_samples))\n",
        "\n",
        "            b_set = set(b_indices)\n",
        "            oob_indices = [i for i in range(n_samples) if i not in b_set]\n",
        "\n",
        "            X_b = []\n",
        "            y_b = []\n",
        "            for idx in b_indices:\n",
        "                X_b.append(X[idx])\n",
        "                y_b.append(y[idx])\n",
        "\n",
        "            X_b = np.array(X_b)\n",
        "            y_b = np.array(y_b)\n",
        "\n",
        "            tree = RandomTree(max_depth=self.max_depth,\n",
        "                             samplesPerLeaf=self.min_samples_leaf,\n",
        "                             max_features=self.max_features)\n",
        "            tree.fit(X_b, y_b)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "            for idx in oob_indices:\n",
        "                prediction = tree.predict(X[idx])\n",
        "                self.oob_predictions[idx].append(prediction)\n",
        "\n",
        "        oob_errors = 0\n",
        "        oob_total = 0\n",
        "\n",
        "        for idx, predictions in self.oob_predictions.items():\n",
        "            if len(predictions) > 0:\n",
        "                counts = {}\n",
        "                for pred in predictions:\n",
        "                    if pred not in counts:\n",
        "                        counts[pred] = 0\n",
        "                    counts[pred] += 1\n",
        "\n",
        "                majority_vote = max(counts, key=counts.get)\n",
        "                if majority_vote != y[idx]:\n",
        "                    oob_errors += 1\n",
        "                oob_total += 1\n",
        "\n",
        "        if oob_total > 0:\n",
        "            self.oob_score = 1 - (oob_errors / oob_total)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "\n",
        "        for sample in X:\n",
        "            votes = []\n",
        "            for tree in self.trees:\n",
        "                votes.append(tree.predict(sample))\n",
        "\n",
        "            counts = {}\n",
        "            for vote in votes:\n",
        "                if vote not in counts:\n",
        "                    counts[vote] = 0\n",
        "                counts[vote] += 1\n",
        "\n",
        "            majority_class = max(counts, key=counts.get)\n",
        "            predictions.append(majority_class)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "class RandomTree(Classifier):\n",
        "    def __init__(self, max_depth=None, samplesPerLeaf=1, max_features=2):\n",
        "        super().__init__(max_depth, samplesPerLeaf)\n",
        "        self.max_features = max_features\n",
        "\n",
        "    def best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        if m <= 1:\n",
        "            return None, None\n",
        "\n",
        "        min_gini = 1\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "\n",
        "        feature_indices = list(range(self.num_dims))\n",
        "        if len(feature_indices) > self.max_features:\n",
        "            feature_indices = sample(feature_indices, self.max_features)\n",
        "\n",
        "        for feature in feature_indices:\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                left_idx = []\n",
        "                for i in range(m):\n",
        "                    if X[i][feature] <= threshold:\n",
        "                        left_idx.append(i)\n",
        "\n",
        "                if len(left_idx) < self.samplesPerLeaf or (m - len(left_idx)) < self.samplesPerLeaf:\n",
        "                    continue\n",
        "\n",
        "                left_y = []\n",
        "                right_y = []\n",
        "                for i in range(m):\n",
        "                    if i in left_idx:\n",
        "                        left_y.append(y[i])\n",
        "                    else:\n",
        "                        right_y.append(y[i])\n",
        "\n",
        "                num_left = len(left_y)\n",
        "                num_right = len(right_y)\n",
        "                left_gini = self.gini_impurity(left_y)\n",
        "                right_gini = self.gini_impurity(right_y)\n",
        "\n",
        "                weighted_gini = (num_left / m) * left_gini + (num_right / m) * right_gini\n",
        "\n",
        "                if weighted_gini < min_gini:\n",
        "                    min_gini = weighted_gini\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold"
      ],
      "metadata": {
        "id": "JwGEtajSXlEd"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fennekin2 = RandomForestClassifier(10,3,1,2)\n",
        "fennekin2.fit(X,y)\n",
        "# Printing scores\n",
        "print(f\"OOB Score: {fennekin2.oob_score * 100:.2f}%\")\n",
        "print(f\"OOb Error: {1-fennekin2.oob_score: .2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc-uA79SYNZ9",
        "outputId": "0810a1e7-fadb-4c0c-9dde-3903906721a2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 42.86%\n",
            "OOb Error:  0.57\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}